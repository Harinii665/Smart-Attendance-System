{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install cmake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade pip setuptools wheel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install dlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install face_recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Photo 1/50 saved as dataset/Mohana_1.jpg\n",
      "Photo 2/50 saved as dataset/Mohana_2.jpg\n",
      "Photo 3/50 saved as dataset/Mohana_3.jpg\n",
      "Photo 4/50 saved as dataset/Mohana_4.jpg\n",
      "Photo 5/50 saved as dataset/Mohana_5.jpg\n",
      "Photo 6/50 saved as dataset/Mohana_6.jpg\n",
      "Photo 7/50 saved as dataset/Mohana_7.jpg\n",
      "Photo 8/50 saved as dataset/Mohana_8.jpg\n",
      "Photo 9/50 saved as dataset/Mohana_9.jpg\n",
      "Photo 10/50 saved as dataset/Mohana_10.jpg\n",
      "Photo 11/50 saved as dataset/Mohana_11.jpg\n",
      "Photo 12/50 saved as dataset/Mohana_12.jpg\n",
      "Photo 13/50 saved as dataset/Mohana_13.jpg\n",
      "Photo 14/50 saved as dataset/Mohana_14.jpg\n",
      "Photo 15/50 saved as dataset/Mohana_15.jpg\n",
      "Photo 16/50 saved as dataset/Mohana_16.jpg\n",
      "Photo 17/50 saved as dataset/Mohana_17.jpg\n",
      "Photo 18/50 saved as dataset/Mohana_18.jpg\n",
      "Photo 19/50 saved as dataset/Mohana_19.jpg\n",
      "Photo 20/50 saved as dataset/Mohana_20.jpg\n",
      "Photo 21/50 saved as dataset/Mohana_21.jpg\n",
      "Photo 22/50 saved as dataset/Mohana_22.jpg\n",
      "Photo 23/50 saved as dataset/Mohana_23.jpg\n",
      "Photo 24/50 saved as dataset/Mohana_24.jpg\n",
      "Photo 25/50 saved as dataset/Mohana_25.jpg\n",
      "Photo 26/50 saved as dataset/Mohana_26.jpg\n",
      "Photo 27/50 saved as dataset/Mohana_27.jpg\n",
      "Photo 28/50 saved as dataset/Mohana_28.jpg\n",
      "Photo 29/50 saved as dataset/Mohana_29.jpg\n",
      "Photo 30/50 saved as dataset/Mohana_30.jpg\n",
      "Photo 31/50 saved as dataset/Mohana_31.jpg\n",
      "Photo 32/50 saved as dataset/Mohana_32.jpg\n",
      "Photo 33/50 saved as dataset/Mohana_33.jpg\n",
      "Photo 34/50 saved as dataset/Mohana_34.jpg\n",
      "Photo 35/50 saved as dataset/Mohana_35.jpg\n",
      "Photo 36/50 saved as dataset/Mohana_36.jpg\n",
      "Photo 37/50 saved as dataset/Mohana_37.jpg\n",
      "Photo 38/50 saved as dataset/Mohana_38.jpg\n",
      "Photo 39/50 saved as dataset/Mohana_39.jpg\n",
      "Photo 40/50 saved as dataset/Mohana_40.jpg\n",
      "Photo 41/50 saved as dataset/Mohana_41.jpg\n",
      "Photo 42/50 saved as dataset/Mohana_42.jpg\n",
      "Photo 43/50 saved as dataset/Mohana_43.jpg\n",
      "Photo 44/50 saved as dataset/Mohana_44.jpg\n",
      "Photo 45/50 saved as dataset/Mohana_45.jpg\n",
      "Photo 46/50 saved as dataset/Mohana_46.jpg\n",
      "Photo 47/50 saved as dataset/Mohana_47.jpg\n",
      "Photo 48/50 saved as dataset/Mohana_48.jpg\n",
      "Photo 49/50 saved as dataset/Mohana_49.jpg\n",
      "Photo 50/50 saved as dataset/Mohana_50.jpg\n",
      "Captured 50 photos for Mohana.\n"
     ]
    }
   ],
   "source": [
    "#1\n",
    "#cpaturing photos\n",
    "# Import necessary libraries\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "# Ask the user to enter their name\n",
    "user_name = input(\"Enter your name: \").strip()\n",
    "\n",
    "# Initialize the camera\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Create a directory for storing the dataset\n",
    "if not os.path.exists(\"dataset\"):\n",
    "    os.makedirs(\"dataset\")\n",
    "\n",
    "# Create a dataset\n",
    "count = 0\n",
    "max_photos = 50 # Set the number of photos to capture\n",
    "while count < max_photos:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to capture image. Exiting...\")\n",
    "        break\n",
    "    cv2.imshow(\"Capturing Photos\", frame)\n",
    "    \n",
    "    # Save the current frame as an image\n",
    "    count += 1\n",
    "    filename = f\"dataset/{user_name}_{count}.jpg\"  # Save photo with number\n",
    "    cv2.imwrite(filename, frame)\n",
    "    print(f\"Photo {count}/{max_photos} saved as {filename}\")\n",
    "    \n",
    "    # Wait for a short duration before capturing the next photo\n",
    "    cv2.waitKey(100)  # 100ms delay between captures\n",
    "\n",
    "# Release the camera and close the window\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(f\"Captured {count} photos for {user_name}.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2\n",
    "#training data\n",
    "# Import necessary libraries\n",
    "import face_recognition\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "# Create a directory for storing the embeddings\n",
    "if not os.path.exists(\"embeddings\"):\n",
    "    os.makedirs(\"embeddings\")\n",
    "\n",
    "# Load the images and extract names\n",
    "image_paths = [os.path.join(\"dataset\", f) for f in os.listdir(\"dataset\")]\n",
    "embeddings = []\n",
    "names = []\n",
    "for image_path in image_paths:\n",
    "    # Extract the name from the file path (ignoring numbering)\n",
    "    name = os.path.basename(image_path).split('_')[0]\n",
    "    image = face_recognition.load_image_file(image_path)\n",
    "    face_locations = face_recognition.face_locations(image)\n",
    "    face_encodings = face_recognition.face_encodings(image, face_locations)\n",
    "    if len(face_encodings) == 1:\n",
    "        embeddings.append(face_encodings[0])\n",
    "        names.append(name)\n",
    "\n",
    "# Save the embeddings and names\n",
    "np.save(\"embeddings/embeddings.npy\", embeddings)\n",
    "with open(\"embeddings/names.json\", \"w\") as f:\n",
    "    json.dump(names, f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attendance marked for Mohana\n"
     ]
    }
   ],
   "source": [
    "#3\n",
    "#recognition and attendance marking\n",
    "import cv2\n",
    "import json\n",
    "import face_recognition\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# Load the embeddings from .npy file\n",
    "embeddings = np.load(\"embeddings/embeddings.npy\")\n",
    "\n",
    "# Initialize the camera\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open camera.\")\n",
    "    exit()\n",
    "\n",
    "# Ensure the attendance file exists with valid JSON content\n",
    "if not os.path.exists(\"attendance.json\"):\n",
    "    with open(\"attendance.json\", \"w\") as f:\n",
    "        json.dump([], f)  # Write an empty list\n",
    "\n",
    "# Load the attendance data\n",
    "try:\n",
    "    with open(\"attendance.json\", \"r\") as f:\n",
    "        attendance = json.load(f)\n",
    "        if not isinstance(attendance, list):  # Ensure itâ€™s a list\n",
    "            attendance = []\n",
    "except (FileNotFoundError, json.JSONDecodeError):\n",
    "    attendance = []  # Create an empty list if no file exists or it's empty\n",
    "\n",
    "# Load known names from names.json\n",
    "with open(\"embeddings/names.json\", \"r\") as f:\n",
    "    names = json.load(f)\n",
    "\n",
    "# Create a set to track attendance for the current session\n",
    "marked_in_session = set()\n",
    "\n",
    "# Main loop to process the video frames\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Find all face locations and encodings in the current frame\n",
    "    face_locations = face_recognition.face_locations(frame)\n",
    "    face_encodings = face_recognition.face_encodings(frame, face_locations)\n",
    "\n",
    "    for (top, right, bottom, left), face_encoding in zip(face_locations, face_encodings):\n",
    "        # Compare faces with known embeddings\n",
    "        matches = face_recognition.compare_faces(embeddings, face_encoding)\n",
    "        face_distances = face_recognition.face_distance(embeddings, face_encoding)\n",
    "        best_match_index = np.argmin(face_distances) if face_distances.size > 0 else -1\n",
    "\n",
    "        if best_match_index != -1 and matches[best_match_index]:\n",
    "            name = names[best_match_index]  # Retrieve username\n",
    "\n",
    "            # Mark attendance if not already marked in this session\n",
    "            if name not in marked_in_session:\n",
    "                attendance.append({\n",
    "                    \"name\": name,\n",
    "                    \"time\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "                })\n",
    "                marked_in_session.add(name)  # Add to the session set\n",
    "                print(f\"Attendance marked for {name}\")\n",
    "\n",
    "            # Draw a rectangle around the face and put the name\n",
    "            cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, name, (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "        else:\n",
    "            # Mark the face as \"Unknown\" if no match is found\n",
    "            cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), 2)\n",
    "            cv2.putText(frame, \"Unknown\", (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 255), 2)\n",
    "\n",
    "    # Show the frame with bounding boxes and names\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "\n",
    "    # Save attendance to the JSON file after each recognition\n",
    "    with open(\"attendance.json\", \"w\") as f:\n",
    "        json.dump(attendance, f, indent=4)\n",
    "\n",
    "    # Exit on pressing 'q'\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "# Clean up\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4\n",
    "#writing attendance in excel\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Load the attendance log from the JSON file\n",
    "with open('attendance.json', 'r') as f:\n",
    "    attendance_log = json.load(f)\n",
    "attendance_list=[{\"User\":i['name'],\"Timestamp\":i['time']} for i in  attendance_log ]\n",
    "# Convert the attendance log to a Pandas dataframe\n",
    "df = pd.DataFrame(attendance_list)\n",
    "\n",
    "# Write the attendance data to an Excel file\n",
    "df.to_excel('attendance_log.xlsx', index=False, engine='openpyxl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "{newenv}",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
